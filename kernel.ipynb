{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greeting\n",
    "[u++](https://www.kaggle.com/sishihara/hypothesis-and-visualization-for-titanic-in-kaggle), Thank you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "e12020f7-4f94-4ecc-9007-9b7a6e7458a6",
    "_uuid": "1fecb0980d8d422ec0f005c4bfd6225385c2c60f"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re as re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d49e43e8-0dc0-41b7-afd0-60acc96e9f07",
    "_uuid": "4ecd55c5bd48390d026eeb6ae8de0a7ace0d4ada"
   },
   "source": [
    "## Loading datasets\n",
    "Check column item explanation on [Data Dictionary](https://www.kaggle.com/c/titanic/data)\n",
    "\n",
    "`train.append(test)`でcsvをジョイント。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "9c963eb3-04ac-422c-bc0c-4373bda6880e",
    "_uuid": "95f406c4d2f1dab6744ea248b80e3a535c652450"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./input/train.csv\")\n",
    "test = pd.read_csv(\"./input/test.csv\")\n",
    "data = train.append(test) # The entire data: train + test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "687a06ef-2686-4772-ac24-5e413adbda6d",
    "_uuid": "3846eff13d723fa6ff10117fc3ebc46f266b210f"
   },
   "source": [
    "# Features Engineering\n",
    "[特徴エンジニアリング](https://docs.microsoft.com/ja-jp/azure/machine-learning/team-data-science-process/create-features). このプロセスは、データ内の既存の生の特徴から、関連する特徴を作成し、学習アルゴリズムの予測力を高めようとする。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "09253274-14c1-4ca9-a078-85229acba814",
    "_uuid": "234454857fff5bd61026c51cefd5eaee4e6a1879"
   },
   "source": [
    "## 1. Pclass ##\n",
    "There is no missing value on this feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b84a4c4b-9db2-4626-8a28-9817084eb554",
    "_uuid": "610bb44d64b400e7bafbf4d6a3295c7a43f1df23"
   },
   "source": [
    "## 2. Sex ##\n",
    "There is no missing value on this feature, but mapping is needed.\n",
    "\n",
    "`str.replace(old, new[, count])`: `old`を`new`にする。\n",
    "\n",
    "`train`変数: train.csvを読み込んだもの。\n",
    "\n",
    "`test`変数: test.csvを読み込んだもの。\n",
    "\n",
    "[`DataFrame`の引数`inplace`](https://note.nkmk.me/python-pandas-dataframe-rename/): 引数inplaceをTrueにすると、元のDataFrameが変更される。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "27c06d9c-61e1-4ba8-9cfc-81a2dd27390a",
    "_uuid": "07b661b256360d39ec561f465735042f37eee257"
   },
   "outputs": [],
   "source": [
    "train['Sex'].replace(['male','female'],[0,1], inplace=True)\n",
    "test['Sex'].replace(['male','female'],[0,1], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2ab02454-4dfa-4aa3-ae94-7029b86ef69e",
    "_uuid": "2cb8d46258c4b14ec678543f99f4f5789d60b22f"
   },
   "source": [
    "## 3. Embarked\n",
    "Embarked feature has some missing values, filled with the most occurred value ( 'S' ).\n",
    "\n",
    "[`fillna()`メソッド](https://note.nkmk.me/python-pandas-nan-dropna-fillna/): 欠損値を他の値に置換（穴埋め）する.\n",
    "[`map()`の引数に辞書を指定](https://note.nkmk.me/python-pandas-map-replace/): `map()`の引数に辞書`dict（{key: value}）`を指定すると、`key`と一致する要素が`value`に置換."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "1329072e-5fc0-4aea-bc7b-ec7c27aff260",
    "_uuid": "5268b97889ec90508f501697d9e8d497398e0c46"
   },
   "outputs": [],
   "source": [
    "data['Embarked'].fillna(('S'), inplace=True)\n",
    "data['Embarked'] = data['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "\n",
    "train['Embarked'] = data['Embarked'][:len(train)]\n",
    "test['Embarked'] = data['Embarked'][len(train):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8c33619e-a180-4c12-9f63-e7b3023206cd",
    "_uuid": "382a7882e2ae3144513f8ffea8478b4e24e8df0f"
   },
   "source": [
    "## 4. Fare ##\n",
    "Fare also has some missing value and replaced them with mean, and categorized into 4 ranges.\n",
    "[`np.mean`](https://deepage.net/features/numpy-average.html#npmean): 純粋に要素の平均を求める. つまり、`Fare`の欠損値は平均で埋める、ということ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "fd9b2edd-cf75-4ad8-a100-5ca06cb53f7b",
    "_uuid": "161a7a829ad6a45b7745655b1713888a6778818f"
   },
   "outputs": [],
   "source": [
    "data['Fare'].fillna(np.mean(data['Fare']), inplace=True)\n",
    "data['Categorical_Fare'] = pd.qcut(data['Fare'], 4, labels=False)\n",
    "\n",
    "train['Categorical_Fare'] = data['Categorical_Fare'][:len(train)]\n",
    "test['Categorical_Fare'] = data['Categorical_Fare'][len(train):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1ea2fef1-ec32-4688-9030-63bafed9692c",
    "_uuid": "0c6cb694c63862e8f1d805fdcd54769312aae246"
   },
   "source": [
    "## 5. Age ##\n",
    "There are plenty of missing values in this feature. Generate random numbers between (mean - std) and (mean + std), categorized into 5 range.\n",
    "\n",
    "- `numpy.mean()`: 平均\n",
    "- `.std()`: 配列に含まれる要素のデータの散らばり具合を示す指標の１つとなる標準偏差を求める。\n",
    "- `pd.cut()`: ビニング処理（ビン分割）。連続値を任意の境界値で区切りカテゴリ分けして離散値に変換する処理のこと。機械学習の前処理として行われることが多い。値を元にビン分割。最大値と最小値の間を等間隔で分割し、境界値を指定して分割する。\n",
    "\n",
    "### 平均から標準偏差を求める流れとなる\n",
    "- 標準偏差: 標準偏差を求めるには、分散（それぞれの数値と平均値の差の二乗平均）の正の平方根を取ります。 データが平均値の周りに集中していれば標準偏差は小さくなり、逆に平均値から広がっていれば標準偏差は大きくなります。\n",
    "- 偏差 = 個人の点数 - 平均点。偏差が大きくなればなるほど平均から外れている。偏差の平均値を取れば、全体が平均からどれだけずれているかがわかる。\n",
    "- 偏差の問題点: 平均値からどれほど離れているのかを数字で表した偏差ですが、偏差は偏差の平均を取ると常に０になってしまうのです。偏差には、プラスとマイナスの値がそれぞれ出現し、平均を取るとこれらがお互いに打ち消しあい、すべて加えると０になってしまうというわけです。\n",
    "- 偏差の問題点を解決する偏差平方: 偏差 ** 2 = {(自分の取った点) - (平均点)} ** 2。これで負の数が正の数になる。\n",
    "- 分散の問題点1: 平方をすると数値が大きくなりすぎる。\n",
    "- 分散の問題点2: 偏差を平方したことで単位が変わってしまう。\n",
    "- 分散の問題点を解決するのが標準偏差。 `math.sqrt('分散')`。分散の平方根を取る。\n",
    "\n",
    "### 乱数の生成\n",
    "`random.randint(age_avg - age_std, age_avg + age_std)`は平均マイナス標準偏差で最低ラインの年齢、平均プラス標準偏差で上位ラインの年齢の間で乱数を生成させる。\n",
    "\n",
    "### 参考リンク\n",
    "- [nkmk](https://note.nkmk.me/python-numpy-ndarray-sum-mean-axis/)\n",
    "- [平均から偏差までの流れを追う](https://tinyurl.com/y7u648lf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "5717373d-91ce-4cfd-a579-ef7dab192771",
    "_uuid": "42f1ebda5705d5272ea350bfd00e66c2f946a66e"
   },
   "outputs": [],
   "source": [
    "age_avg = data['Age'].mean()\n",
    "age_std = data['Age'].std()\n",
    "\n",
    "data['Age'].fillna(np.random.randint(age_avg - age_std, age_avg + age_std), inplace=True)\n",
    "data['Categorical_Age'] = pd.cut(data['Age'], 5, labels=False)\n",
    "\n",
    "train['Categorical_Age'] = data['Categorical_Age'][:len(train)]\n",
    "test['Categorical_Age'] = data['Categorical_Age'][len(train):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "84deabf4-68d7-4e49-af04-80e12dda61ee",
    "_uuid": "863ab430353620a94113d8b577a13816a48e3553"
   },
   "source": [
    "## 6. Name ##\n",
    "Inside this feature, there are titles of people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "1ab17ba4-1d23-46e8-806f-7fe7920247e7",
    "_uuid": "3c21c7500255426797e93abf25c4c6e43aef063c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dropping Title feature\n",
    "def get_title(name):\n",
    "\ttitle_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "\t# If the title exists, extract and return it.\n",
    "\tif title_search:\n",
    "\t\treturn title_search.group(1)\n",
    "\treturn \"\"\n",
    "\n",
    "data['Title'] = data['Name'].apply(get_title)\n",
    "\n",
    "data['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n",
    " \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare', inplace=True)\n",
    "\n",
    "data['Title'].replace(['Mlle','Ms','Mme'],['Miss','Miss','Mrs'], inplace=True)\n",
    "\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "data['Title'] = data['Title'].map(title_mapping)\n",
    "data['Title'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b10e8bd3-bd55-40f4-992f-cfbe69238bc3",
    "_uuid": "2f9008e863b7b44cf94598d65d34f810cb42ec5d"
   },
   "source": [
    "## Data Cleaning ##\n",
    "`pandas.DataFrame`の行・列を指定して削除するには`drop()`メソッドを使う。\n",
    "- `axis = 0`で行を削除\n",
    "- `axis = 1`で列を削除\n",
    "\n",
    "### 参考サイト\n",
    "- [pandas.df.drop](https://note.nkmk.me/python-pandas-drop/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "d3f3527c-8758-41c2-bbe3-14b604b2d317",
    "_uuid": "f7341a6f089464180e94d5e09d1071e0350cff3d"
   },
   "outputs": [],
   "source": [
    "delete_columns = ['Fare', 'Age', 'Name', 'PassengerId', 'SibSp', 'Parch', 'Ticket', 'Cabin']\n",
    "train.drop(delete_columns, axis = 1, inplace = True)\n",
    "test.drop(delete_columns, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "03d91a2b-08da-4593-8c1e-840fb7bec469",
    "_uuid": "768050e7f210d95ba28226ada778e763d21c97f8",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Categorical_Fare</th>\n",
       "      <th>Categorical_Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex  Embarked  Categorical_Fare  Categorical_Age\n",
       "0         0       3    0         0                 0                1\n",
       "1         1       1    1         1                 3                2\n",
       "2         1       3    1         0                 1                1\n",
       "3         1       1    1         0                 3                2\n",
       "4         0       3    0         0                 1                2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Categorical_Fare</th>\n",
       "      <th>Categorical_Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex  Embarked  Categorical_Fare  Categorical_Age\n",
       "0       3    0         2                 0                2\n",
       "1       3    1         0                 0                2\n",
       "2       2    0         2                 1                3\n",
       "3       3    0         0                 1                1\n",
       "4       3    1         0                 1                1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "19f52c93-701c-4ae1-ad7c-0c89004bc1a0",
    "_uuid": "d2f7f7fd519f1fcc160304783c8b440e5cb552da"
   },
   "source": [
    "# Classification #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5b91437e-845e-4e3f-a20e-19db3d7a8540",
    "_uuid": "52d1886521f05ac5043ef734d94aadf59cc7a073"
   },
   "source": [
    " - **Creating X and y**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "2fdafbf3-62cc-4365-8168-7e149f8b51f0",
    "_uuid": "94e2b9da92605974f2e7575f85b10abf98a0d6b4"
   },
   "outputs": [],
   "source": [
    "X = train.drop('Survived', axis = 1)\n",
    "y = train['Survived']\n",
    "X_test = test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "84ece816-177c-473e-92ae-620c5fe50be6",
    "_uuid": "fd73849d6b1805fa835b1031a1e2e812e0ef68e3"
   },
   "source": [
    " - **Scaling features**\n",
    "   - `sklearn.preprocessing.StandardScaler`: 標準化して特徴量の尺度を揃えるために使う。\n",
    "   - `fit_transform()`: `StandardScaler`モジュールで使えるメソッド。パラメータ計算とデータ変換をまとめて実行する。\n",
    " - **参考サイト**\n",
    "   - [sklearn StandardScaler で標準化の効果を確かめる－python](http://ailaby.com/scaler/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "6f077d59-c48d-41b2-82b2-7cd325ed4aab",
    "_uuid": "fc95cee7c61fee94005453e2b97598f69267ca29"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "std_scaler = StandardScaler()\n",
    "X = std_scaler.fit_transform(X)\n",
    "X_test = std_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bd37c2af-8981-43b0-8a60-da278d130073",
    "_uuid": "e59cb01ea58d9aaf401655bee18c682976956f00"
   },
   "source": [
    "## Grid Search CV ##\n",
    " \n",
    " Here I use KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "0baa26fd-c625-44a0-9411-b2479ace87ab",
    "_uuid": "670108e53958cb3378a2d7f35043c698cedb05be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 300 candidates, totalling 3000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done  80 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=10)]: Done 980 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=10)]: Done 2480 tasks      | elapsed:    7.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8563750426198434\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=11, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
      "           weights='distance')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done 3000 out of 3000 | elapsed:    8.4s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "n_neighbors = list(range(5,20,1))\n",
    "algorithm = ['auto']\n",
    "weights = ['uniform', 'distance']\n",
    "leaf_size = list(range(1,50,5))\n",
    "hyperparams = {'algorithm': algorithm, 'weights': weights, 'leaf_size': leaf_size, \n",
    "               'n_neighbors': n_neighbors}\n",
    "gd = GridSearchCV(estimator = KNeighborsClassifier(), param_grid = hyperparams, verbose=True, \n",
    "                cv=10, scoring = \"roc_auc\", n_jobs=10)\n",
    "gd.fit(X, y)\n",
    "print(gd.best_score_)\n",
    "print(gd.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b91368fc-7671-497c-bea2-bba3b857633c",
    "_uuid": "f2170452b8a8f2fa89f4b5e9bb221e488bf42282"
   },
   "source": [
    " - **Using a model found by grid searching**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "2ab86ce3-6bc2-46d1-9324-cf496bb1ea06",
    "_uuid": "485df2df733917a8bbf405a9a9eabf792ecb89e4"
   },
   "outputs": [],
   "source": [
    "gd.best_estimator_.fit(X, y)\n",
    "y_pred = gd.best_estimator_.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a37e176c-3b55-43ab-b358-324dc384ceef",
    "_uuid": "d4d6df3e6c40063309ea72f4d4cea51cf616fd80"
   },
   "source": [
    "- **Making submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "8111500e-330c-411e-a742-66b9d4c5cb2c",
    "_uuid": "40858051e4f458835f937275be4dfe3dfa68b25f"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'../input/test.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-c18f425a2cf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../input/test.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PassengerId'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Survived'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"submission.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'../input/test.csv' does not exist"
     ]
    }
   ],
   "source": [
    "temp = pd.DataFrame(pd.read_csv(\"../input/test.csv\")['PassengerId'])\n",
    "temp['Survived'] = list(map(int, y_pred))\n",
    "temp.to_csv(\"submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "31e4aad1-6656-4de6-accc-433412462c40",
    "_uuid": "8fbf60d67d52c02451b46de00ce927aadfd4c744",
    "collapsed": true
   },
   "source": [
    "# New Feature Creation #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6da613df9f55f5041d4be1c9811d5a3ec2c9400b"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f45e7a251f5f0caaf86f412261062f610e91b058"
   },
   "source": [
    "Create new feature called Family Size, just Parch + SibSp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "facd2ef9df7a0b8800d836224571a4c35cbd7f7a"
   },
   "outputs": [],
   "source": [
    "data['Family_Size'] = data['Parch'] + data['SibSp'] + 1\n",
    "\n",
    "train['Family_Size'] = data['Family_Size'][:len(train)]\n",
    "test['Family_Size'] = data['Family_Size'][len(train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "de21f8bda41a7253a191d49c170e5b99fb68054a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='Family_Size', data = train, hue = 'Survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cc38d610216632d68327388bb2b172c26fe48073"
   },
   "source": [
    "You can see 2 findings:\n",
    "1. Family_Size >= 5 may also lead to bad survival rate.\n",
    "1. Family_Size == 1 may lead to bad survival rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7b7fb933b36c52594e10c99584c494ecafae4ae8"
   },
   "outputs": [],
   "source": [
    "X = train.drop('Survived', axis = 1)\n",
    "y = train['Survived']\n",
    "X_test = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dd75b7d758e70835858cfd2041f3d5961afc0663"
   },
   "outputs": [],
   "source": [
    "std_scaler = StandardScaler()\n",
    "X = std_scaler.fit_transform(X)\n",
    "X_test = std_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f05a96040440e0cb53128aac8e114ad1a771638a"
   },
   "outputs": [],
   "source": [
    "n_neighbors = list(range(5,20,1))\n",
    "algorithm = ['auto']\n",
    "weights = ['uniform', 'distance']\n",
    "leaf_size = list(range(1,50,5))\n",
    "hyperparams = {'algorithm': algorithm, 'weights': weights, 'leaf_size': leaf_size, \n",
    "               'n_neighbors': n_neighbors}\n",
    "gd = GridSearchCV(estimator = KNeighborsClassifier(), param_grid = hyperparams, verbose=True, \n",
    "                cv=10, scoring = \"roc_auc\", n_jobs=10)\n",
    "gd.fit(X, y)\n",
    "print(gd.best_score_)\n",
    "print(gd.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "81556b157feddb9f084837eb42d6cda5e4188691"
   },
   "outputs": [],
   "source": [
    "gd.best_estimator_.fit(X, y)\n",
    "y_pred = gd.best_estimator_.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4013ce438cc3e672a90557451ed80a7a8e2bdd78"
   },
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(pd.read_csv(\"../input/test.csv\")['PassengerId'])\n",
    "temp['Survived'] = list(map(int, y_pred))\n",
    "temp.to_csv(\"submission_add_family_size.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a70fca32c7f09b7c7155dedae6ee001656a07c9d"
   },
   "source": [
    "Let's go further and categorize people to check whether they are alone in this ship or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "231c870086cb82091a6571886035ef9acf1b433a"
   },
   "outputs": [],
   "source": [
    "data['IsAlone'] = 0\n",
    "data.loc[data['Family_Size'] == 1, 'IsAlone'] = 1\n",
    "\n",
    "train['IsAlone'] = data['IsAlone'][:len(train)]\n",
    "test['IsAlone'] = data['IsAlone'][len(train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dcd47b07c15318b7dad9e32b4edcddc7905d9d95"
   },
   "outputs": [],
   "source": [
    "X = train.drop('Survived', axis = 1)\n",
    "y = train['Survived']\n",
    "X_test = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "498178be278faf18a4ef686511609bf480d234e7"
   },
   "outputs": [],
   "source": [
    "std_scaler = StandardScaler()\n",
    "X = std_scaler.fit_transform(X)\n",
    "X_test = std_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e289ab3240f882bbb12027f3c4561e35bd54410b"
   },
   "outputs": [],
   "source": [
    "n_neighbors = list(range(5,20,1))\n",
    "algorithm = ['auto']\n",
    "weights = ['uniform', 'distance']\n",
    "leaf_size = list(range(1,50,5))\n",
    "hyperparams = {'algorithm': algorithm, 'weights': weights, 'leaf_size': leaf_size, \n",
    "               'n_neighbors': n_neighbors}\n",
    "gd = GridSearchCV(estimator = KNeighborsClassifier(), param_grid = hyperparams, verbose=True, \n",
    "                cv=10, scoring = \"roc_auc\", n_jobs=10)\n",
    "gd.fit(X, y)\n",
    "print(gd.best_score_)\n",
    "print(gd.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f82a38288a8f01c926a30d0efb63e99fe0af394b"
   },
   "outputs": [],
   "source": [
    "gd.best_estimator_.fit(X, y)\n",
    "y_pred = gd.best_estimator_.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b79b006e1acc1ee0b1b4c1e79737d25290388463"
   },
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(pd.read_csv(\"../input/test.csv\")['PassengerId'])\n",
    "temp['Survived'] = list(map(int, y_pred))\n",
    "temp.to_csv(\"submission_add_family_size_and_isalone.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d51cef4a043bbab7560dc972a948d96a0b369760"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
